{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d25da37b-21c7-4515-bcbd-1516c7903925",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, OrdinalEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4b6f25a2-0548-4aaf-84be-a5c2fb5193a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading datasets\n",
    "train_df = pd.read_csv('train_final.csv')\n",
    "test_df = pd.read_csv('test_final.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bfef8316-fc5c-4163-a2c7-9fd58d4ba917",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Check for '?' and NaN values in each column for both train and test sets\n",
    "def check_missing_values(df, name):\n",
    "    print(f\"\\n--- {name} Data ---\")\n",
    "    nan_counts = df.isnull().sum()  # Counts of NaN values\n",
    "    question_mark_counts = (df == '?').sum()  # Counts of '?' values\n",
    "\n",
    "    missing_value_summary = pd.DataFrame({\n",
    "        'NaN Count': nan_counts,\n",
    "        '? Count': question_mark_counts\n",
    "    })\n",
    "\n",
    "    print(missing_value_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "32bbefea-a12d-4019-9dec-e116811c0c4d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Train Data ---\n",
      "                NaN Count  ? Count\n",
      "age                     0        0\n",
      "workclass               0     1437\n",
      "fnlwgt                  0        0\n",
      "education               0        0\n",
      "education.num           0        0\n",
      "marital.status          0        0\n",
      "occupation              0     1442\n",
      "relationship            0        0\n",
      "race                    0        0\n",
      "sex                     0        0\n",
      "capital.gain            0        0\n",
      "capital.loss            0        0\n",
      "hours.per.week          0        0\n",
      "native.country          0      427\n",
      "income>50K              0        0\n",
      "\n",
      "--- Test Data ---\n",
      "                NaN Count  ? Count\n",
      "ID                      0        0\n",
      "age                     0        0\n",
      "workclass               0     1362\n",
      "fnlwgt                  0        0\n",
      "education               0        0\n",
      "education.num           0        0\n",
      "marital.status          0        0\n",
      "occupation              0     1367\n",
      "relationship            0        0\n",
      "race                    0        0\n",
      "sex                     0        0\n",
      "capital.gain            0        0\n",
      "capital.loss            0        0\n",
      "hours.per.week          0        0\n",
      "native.country          0      430\n"
     ]
    }
   ],
   "source": [
    "# Check missing values in train and test data - only ? should be there\n",
    "check_missing_values(train_df, 'Train')\n",
    "check_missing_values(test_df, 'Test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ab156960-dcae-48be-bb25-165f4b3eee7e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Replace '?' with NaN to handle missing values\n",
    "train_df.replace('?', pd.NA, inplace=True)\n",
    "test_df.replace('?', pd.NA, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "03047885-2e15-4f07-8c3f-8cdeb744b9e9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Train Data ---\n",
      "                NaN Count  ? Count\n",
      "age                     0        0\n",
      "workclass            1437        0\n",
      "fnlwgt                  0        0\n",
      "education               0        0\n",
      "education.num           0        0\n",
      "marital.status          0        0\n",
      "occupation           1442        0\n",
      "relationship            0        0\n",
      "race                    0        0\n",
      "sex                     0        0\n",
      "capital.gain            0        0\n",
      "capital.loss            0        0\n",
      "hours.per.week          0        0\n",
      "native.country        427        0\n",
      "income>50K              0        0\n",
      "\n",
      "--- Test Data ---\n",
      "                NaN Count  ? Count\n",
      "ID                      0        0\n",
      "age                     0        0\n",
      "workclass            1362        0\n",
      "fnlwgt                  0        0\n",
      "education               0        0\n",
      "education.num           0        0\n",
      "marital.status          0        0\n",
      "occupation           1367        0\n",
      "relationship            0        0\n",
      "race                    0        0\n",
      "sex                     0        0\n",
      "capital.gain            0        0\n",
      "capital.loss            0        0\n",
      "hours.per.week          0        0\n",
      "native.country        430        0\n"
     ]
    }
   ],
   "source": [
    "# Check missing values in train and test data - only nan should be there\n",
    "check_missing_values(train_df, 'Train')\n",
    "check_missing_values(test_df, 'Test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ec7bab6b-4eba-4a8f-9f20-b1a72f1ba17d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Separating the target variable and features\n",
    "X_train = train_df.drop(columns='income>50K')\n",
    "y_train = train_df['income>50K']\n",
    "X_test = test_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3c06cada-bdbc-4901-ae30-cc8d261f9366",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# FEATURE ENGINEERING - deriving new features and dropping unnecessary one\n",
    "\n",
    "# capital net gain = capital.gain - capital.loss\n",
    "X_train['capital.netgain'] = X_train['capital.gain'] - X_train['capital.loss']\n",
    "X_test['capital.netgain'] = X_test['capital.gain'] - X_test['capital.loss']\n",
    "X_train.drop(columns=['capital.gain', 'capital.loss'], inplace=True)\n",
    "X_test.drop(columns=['capital.gain', 'capital.loss'], inplace=True)\n",
    "\n",
    "# capital indicators based on the derived capital net gain\n",
    "X_train['has_capital_gain'] = (X_train['capital.netgain'] > 0).astype(int)\n",
    "X_train['has_capital_loss'] = (X_train['capital.netgain'] < 0).astype(int)\n",
    "X_test['has_capital_gain'] = (X_test['capital.netgain'] > 0).astype(int)\n",
    "X_test['has_capital_loss'] = (X_test['capital.netgain'] < 0).astype(int)\n",
    "\n",
    "# work_hours_category = creating categories based on hours.per.week\n",
    "X_train['work_hours_category'] = pd.cut(X_train['hours.per.week'], bins=[0, 20, 40, 60, 100],\n",
    "                                        labels=['Part-time', 'Full-time', 'Overtime', 'Extreme'])\n",
    "X_test['work_hours_category'] = pd.cut(X_test['hours.per.week'], bins=[0, 20, 40, 60, 100],\n",
    "                                       labels=['Part-time', 'Full-time', 'Overtime', 'Extreme'])\n",
    "\n",
    "# age_group = creating categories based on age\n",
    "X_train['age_group'] = pd.cut(X_train['age'], bins=[0, 25, 45, 65, 100], \n",
    "                              labels=['Young', 'Middle-aged', 'Senior', 'Elderly'])\n",
    "X_test['age_group'] = pd.cut(X_test['age'], bins=[0, 25, 45, 65, 100], \n",
    "                             labels=['Young', 'Middle-aged', 'Senior', 'Elderly'])\n",
    "\n",
    "# combining relationship and marital.status into family_status  \n",
    "X_train['family_status'] = X_train['relationship'] + '_' + X_train['marital.status']\n",
    "X_test['family_status'] = X_test['relationship'] + '_' + X_test['marital.status']\n",
    "X_train.drop(columns=['relationship', 'marital.status'], inplace=True)\n",
    "X_test.drop(columns=['relationship', 'marital.status'], inplace=True)\n",
    "\n",
    "# DROPPING UNNECESSARY COLUMNS\n",
    "unnecessary_columns = ['fnlwgt']  # dropped based on irrelevance to the problem\n",
    "X_train.drop(columns=unnecessary_columns, inplace=True)\n",
    "X_test.drop(columns=unnecessary_columns, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0e715347-87c3-4f00-8348-a27ca7117eb6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Low Cardinality Categorical Features: ['work_hours_category', 'age_group', 'has_capital_gain', 'has_capital_loss', 'workclass', 'occupation', 'race', 'sex']\n",
      "High Cardinality Categorical Features: ['family_status', 'education', 'native.country']\n"
     ]
    }
   ],
   "source": [
    "numerical_features = ['age', 'education.num', 'hours.per.week', 'capital.netgain']\n",
    "categorical_features = [\n",
    "    'work_hours_category', 'age_group', 'family_status', \n",
    "    'has_capital_gain', 'has_capital_loss', 'workclass', \n",
    "    'occupation', 'education', 'race', 'sex', 'native.country'\n",
    "]\n",
    "\n",
    "# making sure all categorical columns are treated as strings\n",
    "X_train[categorical_features] = X_train[categorical_features].astype(str)\n",
    "X_test[categorical_features] = X_test[categorical_features].astype(str)\n",
    "\n",
    "# Calculate cardinality of categorical features\n",
    "unique_category_counts = X_train[categorical_features].nunique()\n",
    "\n",
    "# Split into low and high cardinality based on the threshold\n",
    "threshold = 15\n",
    "low_cardinality_cols = unique_category_counts[unique_category_counts <= threshold].index.tolist()\n",
    "high_cardinality_cols = unique_category_counts[unique_category_counts > threshold].index.tolist()\n",
    "\n",
    "print(\"Low Cardinality Categorical Features:\", low_cardinality_cols)\n",
    "print(\"High Cardinality Categorical Features:\", high_cardinality_cols)\n",
    "\n",
    "# Preprocessing Pipelines\n",
    "numerical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='mean')),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "categorical_transformer_low = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "categorical_transformer_high = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('ordinal', OrdinalEncoder(handle_unknown='use_encoded_value', unknown_value=-1))\n",
    "])\n",
    "\n",
    "# Combine Preprocessing\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numerical_transformer, numerical_features),\n",
    "        ('cat_low', categorical_transformer_low, low_cardinality_cols),\n",
    "        ('cat_high', categorical_transformer_high, high_cardinality_cols)\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Apply Preprocessing to Data\n",
    "X_train_transformed = preprocessor.fit_transform(X_train)\n",
    "X_test_transformed = preprocessor.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b2429b37-1c7c-4e70-af3b-42b633a4c383",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest - Area Under ROC (AUC) Curve: 0.9642\n"
     ]
    }
   ],
   "source": [
    "# RANDOM FOREST MODEL\n",
    "# Defining parameter grid for Random Forest\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200],  # Number of trees in the forest\n",
    "    'max_depth': [10, 20],       # Maximum depth of each tree\n",
    "    'min_samples_split': [2, 5], # Minimum samples required to split a node\n",
    "    'min_samples_leaf': [1, 2]   # Minimum samples required at a leaf node\n",
    "}\n",
    "\n",
    "# Initializing Random Forest model\n",
    "rf_model = RandomForestClassifier(random_state=0)\n",
    "\n",
    "# Performing grid search to find the best params\n",
    "rf_grid_search = GridSearchCV(\n",
    "    estimator=rf_model,          # Base model\n",
    "    param_grid=param_grid, \n",
    "    cv=3,                        # 3-fold cross-validation\n",
    "    scoring='roc_auc',           # using AUC as the evaluation metric\n",
    "    n_jobs=-1                    # using all available CPU cores\n",
    ")\n",
    "\n",
    "# Fiting the model to the training data\n",
    "rf_grid_search.fit(X_train_transformed, y_train)\n",
    "\n",
    "# Select the best model from the grid search\n",
    "best_rf_model = rf_grid_search.best_estimator_\n",
    "\n",
    "# Now evaluate the best Random Forest model on the training data\n",
    "y_train_pred_proba_rf = best_rf_model.predict_proba(X_train_transformed)[:, 1]  # Get probabilities for class 1\n",
    "rf_auc_score = roc_auc_score(y_train, y_train_pred_proba_rf)  # Calculating AUC score\n",
    "\n",
    "print(f\"Random Forest - Area Under ROC (AUC) Curve: {rf_auc_score:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fc5ab32e-2e54-4880-829e-803a05ab894c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submissions saved: submission_rf_final.csv\n"
     ]
    }
   ],
   "source": [
    "# GENERATE TEST PREDICTIONS AND SUBMISSIONS\n",
    "y_test_pred_proba_rf = best_rf_model.predict_proba(X_test_transformed)[:, 1]\n",
    "\n",
    "submission_file_name = 'submission_rf_final.csv'\n",
    "\n",
    "submission_rf = pd.DataFrame({'ID': X_test.index + 1, 'Prediction': y_test_pred_proba_rf})\n",
    "submission_rf.to_csv(submission_file_name, index=False)\n",
    "\n",
    "print(f\"Submissions saved: {submission_file_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7f8faeea-9564-430e-b516-eae96a22ca21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost - Area Under ROC (AUC) Curve: 0.9452\n"
     ]
    }
   ],
   "source": [
    "# XGBOOST MODEL\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "# Defining parameter grid for XGBoost\n",
    "xgb_param_grid = {\n",
    "    'n_estimators': [100, 200],       # Number of boosting rounds\n",
    "    'max_depth': [3, 5],              # Maximum tree depth for base learners\n",
    "    'learning_rate': [0.01, 0.1],     # Step size shrinkage\n",
    "    'min_child_weight': [1, 3],       # Minimum sum of instance weight needed in a child\n",
    "    'subsample': [0.8, 1.0]           # Subsample ratio of the training set\n",
    "}\n",
    "\n",
    "# Initializing XGBoost model\n",
    "xgb_model = XGBClassifier(random_state=0, use_label_encoder=False, eval_metric='logloss')\n",
    "\n",
    "# Performing grid search to find the best params\n",
    "xgb_grid_search = GridSearchCV(\n",
    "    estimator=xgb_model,          # Base model\n",
    "    param_grid=xgb_param_grid, \n",
    "    cv=3,                         # 3-fold cross-validation\n",
    "    scoring='roc_auc',            # Using AUC as the evaluation metric\n",
    "    n_jobs=-1                     # Using all available CPU cores\n",
    ")\n",
    "\n",
    "# Fitting the model to the training data\n",
    "xgb_grid_search.fit(X_train_transformed, y_train)\n",
    "\n",
    "# Select the best model from the grid search\n",
    "best_xgb_model = xgb_grid_search.best_estimator_\n",
    "\n",
    "# Now evaluate the best XGBoost model on the training data\n",
    "y_train_pred_proba_xgb = best_xgb_model.predict_proba(X_train_transformed)[:, 1]  # Get probabilities for class 1\n",
    "xgb_auc_score = roc_auc_score(y_train, y_train_pred_proba_xgb)  # Calculating AUC score\n",
    "\n",
    "print(f\"XGBoost - Area Under ROC (AUC) Curve: {xgb_auc_score:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2ddcfaad-c813-4a96-b480-57ad86ca7b00",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submissions saved: submission_xgb_final.csv\n"
     ]
    }
   ],
   "source": [
    "# GENERATE TEST PREDICTIONS AND SUBMISSIONS\n",
    "y_test_pred_proba_xgb = best_xgb_model.predict_proba(X_test_transformed)[:, 1]\n",
    "\n",
    "submission_file_name_xgb = 'submission_xgb_final.csv'\n",
    "\n",
    "submission_xgb = pd.DataFrame({'ID': X_test.index + 1, 'Prediction': y_test_pred_proba_xgb})\n",
    "submission_xgb.to_csv(submission_file_name_xgb, index=False)\n",
    "\n",
    "print(f\"Submissions saved: {submission_file_name_xgb}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae4bf81f-9974-4dbf-a48b-4a4791269445",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
